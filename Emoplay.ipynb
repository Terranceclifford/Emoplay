{
  "cells": [
    {
      "metadata": {
        "id": "WCbeUZHIFaRT"
      },
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "30rYfDL9FaRV"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "# Importing Deep Learning Libraries\n",
        "\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense,Input,Dropout,GlobalAveragePooling2D,Flatten,Conv2D,BatchNormalization,Activation,MaxPooling2D\n",
        "from keras.models import Model,Sequential\n",
        "from keras.optimizers import Adam,SGD,RMSprop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xvJjuvYVFaRW"
      },
      "cell_type": "markdown",
      "source": [
        "# Displaying Images"
      ]
    },
    {
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "Bb_jiMOWFaRW"
      },
      "cell_type": "code",
      "source": [
        "picture_size = 48\n",
        "folder_path = \"/content/drive/MyDrive/Final Year Project - 3018/EmotionDataset/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "x6PWb6cAFaRW"
      },
      "cell_type": "code",
      "source": [
        "expression = 'disgust'\n",
        "\n",
        "plt.figure(figsize= (12,12))\n",
        "for i in range(1, 10, 1):\n",
        "    plt.subplot(3,3,i)\n",
        "    img = load_img(folder_path+\"train/\"+expression+\"/\"+\n",
        "                  os.listdir(folder_path + \"train/\" + expression)[i], target_size=(picture_size, picture_size))\n",
        "    plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "d-qUWEXAueZp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44f14497-cd87-4481-8a4f-520f015e1068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "5OHSq5lVFaRX"
      },
      "cell_type": "markdown",
      "source": [
        "# Making Training and Validation Data"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "ekJQZufPFaRX",
        "outputId": "d07ebb89-a9e0-4560-8bd3-877a7919604a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size  = 128\n",
        "\n",
        "datagen_train  = ImageDataGenerator()\n",
        "datagen_val = ImageDataGenerator()\n",
        "\n",
        "train_set = datagen_train.flow_from_directory(folder_path+\"train\",\n",
        "                                              target_size = (picture_size,picture_size),\n",
        "                                              color_mode = \"grayscale\",\n",
        "                                              batch_size=batch_size,\n",
        "                                              class_mode='categorical',\n",
        "                                              shuffle=True)\n",
        "\n",
        "\n",
        "test_set = datagen_val.flow_from_directory(folder_path+\"validation\",\n",
        "                                              target_size = (picture_size,picture_size),\n",
        "                                              color_mode = \"grayscale\",\n",
        "                                              batch_size=batch_size,\n",
        "                                              class_mode='categorical',\n",
        "                                              shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 21826 images belonging to 7 classes.\n",
            "Found 7076 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "kzv38a3ZFaRX"
      },
      "cell_type": "markdown",
      "source": [
        "# Model Building"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "metl04zVFaRY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd8272d0-5665-40b8-a849-997765af1632"
      },
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam,SGD,RMSprop\n",
        "\n",
        "\n",
        "no_of_classes = 7\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "#1st CNN layer\n",
        "model.add(Conv2D(64,(3,3),padding = 'same',input_shape = (48,48,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#2nd CNN layer\n",
        "model.add(Conv2D(128,(5,5),padding = 'same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "model.add(Dropout (0.25))\n",
        "\n",
        "#3rd CNN layer\n",
        "model.add(Conv2D(512,(3,3),padding = 'same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "model.add(Dropout (0.25))\n",
        "\n",
        "#4th CNN layer\n",
        "model.add(Conv2D(512,(3,3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "#Fully connected 1st layer\n",
        "model.add(Dense(256))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "# Fully connected layer 2nd layer\n",
        "model.add(Dense(512))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Dense(no_of_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "opt = Adam(lr = 0.0001)\n",
        "model.compile(optimizer=opt,loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 48, 48, 64)        640       \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 48, 48, 64)        256       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " activation (Activation)     (None, 48, 48, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 24, 24, 64)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 24, 24, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 24, 24, 128)       204928    \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 24, 24, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 24, 24, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 12, 12, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 12, 12, 128)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 12, 12, 512)       590336    \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 12, 12, 512)       2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 12, 12, 512)       0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 6, 6, 512)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 6, 6, 512)         2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 3, 3, 512)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 3, 3, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4608)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               1179904   \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 256)               1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               131584    \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 512)               2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 7)                 3591      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4478727 (17.08 MB)\n",
            "Trainable params: 4474759 (17.07 MB)\n",
            "Non-trainable params: 3968 (15.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "D7REa0CwFaRY"
      },
      "cell_type": "markdown",
      "source": [
        "# Fitting the Model with Training and Validation Data"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "8dhRupFMFaRY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7664df3c-c245-4202-f333-a39ac7989cbf"
      },
      "cell_type": "code",
      "source": [
        "from keras.optimizers import RMSprop,SGD,Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"./model.h5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss',\n",
        "                          min_delta=0,\n",
        "                          patience=3,\n",
        "                          verbose=1,\n",
        "                          restore_best_weights=True\n",
        "                          )\n",
        "\n",
        "reduce_learningrate = ReduceLROnPlateau(monitor='val_loss',\n",
        "                              factor=0.2,\n",
        "                              patience=3,\n",
        "                              verbose=1,\n",
        "                              min_delta=0.0001)\n",
        "\n",
        "callbacks_list = [early_stopping,checkpoint,reduce_learningrate]\n",
        "\n",
        "epochs = 48\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer = Adam(lr=0.001),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "_HGHAwUWFaRY"
      },
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(generator=train_set,\n",
        "                                steps_per_epoch=train_set.n//train_set.batch_size,\n",
        "                                epochs=epochs,\n",
        "                                validation_data = test_set,\n",
        "                                validation_steps = test_set.n//test_set.batch_size,\n",
        "                                callbacks=callbacks_list\n",
        "                                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6ynfN-7yFaRZ"
      },
      "cell_type": "markdown",
      "source": [
        "# Plotting Accuracy & Loss"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "IfQLCpDaFaRZ"
      },
      "cell_type": "code",
      "source": [
        "plt.style.use('dark_background')\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.suptitle('Optimizer : Adam', fontsize=10)\n",
        "plt.ylabel('Loss', fontsize=16)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.ylabel('Accuracy', fontsize=16)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "mtjmS7MvFaRZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4fa9cedd-cdb0-405e-f2c3-82a434887214"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from google.colab import files\n",
        "# Load the Keras model from h5 file\n",
        "model = tf.keras.models.load_model('/content/model.h5')\n",
        "\n",
        "# Save model architecture as JSON\n",
        "model_json = model.to_json()\n",
        "with open('model.json', 'w') as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "# Save model weights\n",
        "model.save_weights('model_weights.h5')\n",
        "files.download('model.json')\n",
        "files.download('model_weights.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4c15166b-bbd5-4190-ae11-a9c72e56b19b\", \"model.json\", 22887)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ebd4b452-db9b-4301-bedc-f5cdeb3b291b\", \"model_weights.h5\", 5411296)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}